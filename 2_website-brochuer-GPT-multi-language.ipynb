{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5522420-7378-48a0-97a3-c1315a104df1",
   "metadata": {},
   "source": [
    "# Brochure Generator (multi-language) Output\n",
    "This Python Jupyter Notebook automates bilingual brochure generation by scraping company websites and using AI to create professional marketing materials in English and a chosen target language. The script combines BeautifulSoup web scraping to extract content, OpenAI's GPT models to filter important pages and generate a compelling copy, and real-time translation for Spanish, German, and French outputs. Through simple configuration variables, users can specify the company name, website URL, and target language—making it an adaptable tool for creating  brochures for customers, investors, and potential recruits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d740e-28f7-414d-9f21-1bf74ec2757b",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "Key imports for web scraping and AI content generation: os/dotenv for environment variables, requests/BeautifulSoup for web scraping, json/typing for data handling, IPython.display for markdown output, and openai for AI content generation. These libraries enable automated creation of bilingual brochures through web scraping and AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922243b3-f744-4dea-bdbb-c30ed1e58780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b205b8-fffd-4b10-b45e-b14582242306",
   "metadata": {},
   "source": [
    "## 2. Define Constants\n",
    "Loads and validates environment variables including the OpenAI API key (checking for proper 'sk-proj-' format and length), then initializes the GPT-4o-mini model client. It provides validation feedback to help users resolve configuration issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4627e-12d7-48fb-b565-53c749d123f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize & constants\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key) > 10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "\n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660f6a9-3f46-4d6f-91da-00f5c323bde9",
   "metadata": {},
   "source": [
    "## 3. Web Scraping Class\n",
    "Website class scrapes web pages to extract titles, text content, and links. It offers a get_contents() method to format data for brochure generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d766ba-1369-4261-87d5-2e5f005cf7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "    url: str\n",
    "    title: str\n",
    "    body: str\n",
    "    links: List[str]\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4083de81-c38d-41d9-94d1-ba70a63d7937",
   "metadata": {},
   "source": [
    "## 4. Filters and Scrapes content or relevant web-pages\n",
    "AI filters and selects relevant company website links (About, Careers, Company pages) for brochure creation. The get_all_details() function scrapes content from these pages and the main page, combining them into a comprehensive text block about the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7913e0d-9efb-4a47-b4cb-8ff784ae1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-shot prompt to cleanup the links\n",
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def get_links_user_prompt(website):\n",
    "    \"\"\"Generate user prompt for extracting relevant links from website\"\"\"\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"Please decide which of these are relevant web links for creating a brochure about a company, respond with the full https URL in JSON format.\" \n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt\n",
    "\n",
    "def get_links(url):\n",
    "    \"\"\"Extract relevant links from a website using OpenAI\"\"\"\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)\n",
    "\n",
    "def get_all_details(url):\n",
    "    \"\"\"Scrape and compile content from main page and relevant linked pages\"\"\"\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292d84a-ba0b-46ae-9e16-49c6498f4655",
   "metadata": {},
   "source": [
    "## 5. Bilingual Generation Functions\n",
    "AI functionality generates bilingual company brochures from website content. The stream_brochure_bilingual() creates real-time English and translated versions, while translate_brochure() handles the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee26b1-b9c7-4e3f-86a9-4c729ef29fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for brochure creation\n",
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for a prospective customer, investor and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers,careers/jobs, and what makes the company unique, if you have that information.\"\n",
    "\n",
    "def get_brochure_user_prompt(company_name, url):\n",
    "    \"\"\"Generate user prompt for brochure creation\"\"\"\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:20_000]  # Truncate if more than 20,000 characters\n",
    "    return user_prompt\n",
    "\n",
    "def translate_brochure(brochure_content, language=\"Spanish\"):\n",
    "    \"\"\"\n",
    "    Translate brochure content to specified language with streaming output\n",
    "    Returns the translated content as a string\n",
    "    \"\"\"\n",
    "    translation_system_prompt = f\"You are a skilled translator. Translate the following brochure text into {language}.\\\n",
    "    Make sure to translate into idiomatic {language}, matching the target language's natural structure, wording and expressions, so it can't be recognised as a translation.\\\n",
    "    Be sure to also meet an appropriate tone, eg a good marketing language in other languages will probably be a bit less boastful than in English.\\\n",
    "    Output the translated brochure in Markdown format.\"\n",
    "    \n",
    "    # Create streaming response for translation\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": translation_system_prompt}, \n",
    "            {\"role\": \"user\", \"content\": brochure_content}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # Collect and display translated content with streaming\n",
    "    translated_response = \"\"\n",
    "    print(f\"\\n\\n## {language} Translation\\n\")\n",
    "    translation_display = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            translated_response += chunk.choices[0].delta.content\n",
    "            # Clean up markdown formatting for display\n",
    "            clean_response = translated_response.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "            update_display(Markdown(clean_response), display_id=translation_display.display_id)\n",
    "    \n",
    "    return translated_response\n",
    "\n",
    "def stream_brochure_bilingual(company_name, url, translation_language=\"Spanish\"):\n",
    "    \"\"\"\n",
    "    Generate and stream brochure in English, then translate and stream in specified language\n",
    "    \"\"\"\n",
    "    print(f\"## 🏢 Creating brochure for {company_name}\")\n",
    "    print(f\"## 🇺🇸 English Version\\n\")\n",
    "    \n",
    "    # Generate English brochure with streaming\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # Collect English response while streaming\n",
    "    english_response = \"\"\n",
    "    english_display = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            english_response += chunk.choices[0].delta.content\n",
    "            clean_response = english_response.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "            update_display(Markdown(clean_response), display_id=english_display.display_id)\n",
    "    \n",
    "    # Translate the complete English brochure\n",
    "    translated_response = translate_brochure(english_response, translation_language)\n",
    "    \n",
    "    return {\n",
    "        \"english\": english_response,\n",
    "        \"translated\": translated_response,\n",
    "        \"language\": translation_language\n",
    "    }\n",
    "\n",
    "# Legacy function for backward compatibility\n",
    "def stream_brochure(company_name, url):\n",
    "    \"\"\"\n",
    "    Original function - now calls the bilingual version but only shows English\n",
    "    Kept for backward compatibility\n",
    "    \"\"\"\n",
    "    result = stream_brochure_bilingual(company_name, url)\n",
    "    return result[\"english\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc9c80-2fd4-428c-918c-6c3c31323199",
   "metadata": {},
   "source": [
    "## 6. Script Settings\n",
    "User specifies the company name, website URL, and target language for bilingual brochure generation. When executed, it creates English and Spanish versions by scraping and translating the company's website content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b77ca-1d84-4247-bfe6-ab79fe5b3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default output is English and German; change to perfered\n",
    "COMPANY_NAME = \"Huggingface\"\n",
    "COMPANY_URL = \"https://huggingface.co/\"\n",
    "TRANSLATION_LANGUAGE = \"French\"  # Options: German, Spanish, French, Italian, Portuguese, etc.\n",
    "\n",
    "# Runs the brochure generator\n",
    "if __name__ == \"__main__\":\n",
    "    stream_brochure_bilingual(COMPANY_NAME, COMPANY_URL, TRANSLATION_LANGUAGE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
